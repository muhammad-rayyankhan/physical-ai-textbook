# ============================================
# CLOUD CONFIGURATION
# ============================================

# Neon PostgreSQL Database
DATABASE_URL=postgresql://user:password@host/database

# Qdrant Cloud Vector Store
QDRANT_URL=https://your-cluster.qdrant.io
QDRANT_API_KEY=your-qdrant-api-key
QDRANT_COLLECTION=textbook_chunks

# Groq API (Free, Fast LLM)
GROQ_API_KEY=your-groq-api-key
GROQ_MODEL=llama-3.1-70b-versatile

# Local Embeddings (Sentence Transformers) - FREE
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2

# Feature Flags
USE_OPENAI_EMBEDDINGS=false
USE_OPENAI_LLM=false

# ============================================
# OPTIONAL: OpenAI Configuration (Not Used)
# ============================================
# Uncomment these if you want to use OpenAI in the future
# OPENAI_API_KEY=sk-proj-your-key-here
# OPENAI_MODEL=gpt-3.5-turbo
# OPENAI_EMBEDDING_MODEL=text-embedding-3-small
# USE_OPENAI_EMBEDDINGS=true
# USE_OPENAI_LLM=true

# Authentication
AUTH_SECRET=your-auth-secret-key
AUTH_URL=http://localhost:8000

# API Configuration
API_HOST=0.0.0.0
API_PORT=8000
CORS_ORIGINS=http://localhost:3000,https://your-domain.vercel.app

# Admin API Key (for ingestion)
ADMIN_API_KEY=your-secure-admin-key

# Environment
ENVIRONMENT=development

# ============================================
# LEGACY: Local Ollama (Not Used in Cloud)
# ============================================
# OLLAMA_BASE_URL=http://localhost:11434
# OLLAMA_MODEL=llama3.2
